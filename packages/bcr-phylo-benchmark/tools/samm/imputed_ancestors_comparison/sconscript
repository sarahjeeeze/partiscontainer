## Compare imputing ancestors to sampling

import os
import pickle
import csv
import numpy as np

from os.path import join
from nestly.scons import SConsWrap
from nestly import Nest
from SCons.Script import Environment, Command, AddOption
from data_paths import SCRATCH_DIR, CUI_DATA_PATH
from hier_motif_feature_generator import HierarchicalMotifFeatureGenerator
from itertools import izip
from common import pick_best_model
from context_model_algo import *

Import('env')
localenv = env.Clone()

# Set up state
base = {'nreps': localenv['NREPS'],
        'output_name': localenv['OUTPUT_NAME']}

nest = SConsWrap(Nest(base_dict=base), '_'+localenv['OUTPUT_NAME'], alias_environment=localenv)

MOTIF_LEN = 5
MUTATING_POSITION = 2
N_CLONAL_FAMILIES = 3000
RATIO_NONZERO = .75
#PENALTY_PARAMS = ",".join(map(str, np.power(10, np.arange(-4.0, -7.0, step=-0.5)).tolist()))
PENALTY_PARAMS = ",".join(map(str, [0]))
PENALTY_PARAMS_SAMPLE = ",".join(map(str, np.power(10, np.arange(-2.0, -7.0, step=-0.5)).tolist()))

@nest.add_target_with_env(localenv)
def generate_theta(env, outdir, c):
    cmd = ['python generate_theta.py',
           '--motif-lens',
           MOTIF_LEN,
           '--positions-mutating',
           MUTATING_POSITION,
           '--nonzero-ratio',
           RATIO_NONZERO,
           '--output-model ${TARGETS[0]}']

    return env.Command(
        [join(outdir, 'true_theta.pkl')],
        [],
        ' '.join(map(str, cmd)))

# Nest for replicates
nest.add(
    'replicate',
    range(localenv['NREPS']),
    label_func='replicate{:02d}'.format)

# Set the seed to be the replicate number.
nest.add(
    'seed',
    lambda c: [c['replicate']],
    create_dir=False)

def write_truth(target, source, env):
    c = env['control']
    with open(str(source[0]), 'r') as f:
        agg_theta, theta = pickle.load(f)

    agg_theta = theta - np.median(theta)

    feat_generator = HierarchicalMotifFeatureGenerator(motif_lens=[MOTIF_LEN])
    motif_list = feat_generator.motif_list

    columns = 'rep motif col theta model'.split()
    data = []
    for col in range(theta.shape[1]):
        for idx, motif in enumerate(motif_list):
            data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'model': 'truth'}
            data_dict['theta'] = agg_theta[idx, col]

            data.append(data_dict)

    with open(str(target[0]), 'wb') as f:
        writer = csv.DictWriter(f, columns)
        writer.writeheader()
        writer.writerows(data)

def truth_to_csv(target, source, env):
    c = env['control']
    with open(str(source[0]), 'r') as f:
        agg_theta, theta = pickle.load(f)

    agg_theta -= np.median(agg_theta)

    feat_generator = HierarchicalMotifFeatureGenerator(motif_lens=[MOTIF_LEN])
    motif_list = feat_generator.motif_list

    mut_columns = ["motif", "mutability"]
    mut_data = []
    sub_columns = ["motif", "A", "C", "G", "T"]
    sub_data = []
    for idx, motif in enumerate(motif_list):
        mut_dict = {'motif': "%s" % motif.upper(), 'mutability': np.exp(agg_theta[idx, 0])}
        mut_data.append(mut_dict)

        sub_dict = {'motif': '%s' % motif.upper()}
        for nuc in 'ACGT':
            sub_dict['%s' % nuc] = 0. if motif[2].upper()==nuc else 1./3
        sub_data.append(sub_dict)

    with open(str(target[0]), 'wb') as f:
        writer = csv.DictWriter(f, mut_columns, delimiter=" ")
        writer.writeheader()
        writer.writerows(mut_data)

    with open(str(target[1]), 'wb') as f:
        writer = csv.DictWriter(f, sub_columns, delimiter=" ")
        writer.writeheader()
        writer.writerows(sub_data)

@nest.add_target_with_env(localenv)
def write_gctree_truth(env, outdir, c):
    return env.Command(
        [join(outdir, 'mut_theta.csv'), join(outdir, 'sub_theta.csv')],
        c['generate_theta'],
        truth_to_csv,
        control=c)

@nest.add_target_with_env(localenv)
def convert_truth(env, outdir, c):
    return env.Command(
        join(outdir, 'true_theta.csv'),
        c['generate_theta'],
        write_truth,
        control=c)

tree_size_dict = [
    #{
    #    'n_taxa': N_CLONAL_FAMILIES,
    #    'n_clonal_families': 2,
    #    'size': 'one_big_tree',
    #},
    {
        'n_taxa': None,
        'n_clonal_families': N_CLONAL_FAMILIES,
        'size': 'realistic',
    },
]

nest.add(
    'tree_size',
    tree_size_dict,
    label_func=lambda c: c['size'])

nest.add(
    'pct_mutated',
    [
        .025,
        #.05,
    ],
    label_func='pct_mutated{:.3f}'.format)

nest.add_aggregate('compare_models', list)

# Targets for simulating fake data
@nest.add_target_with_env(localenv)
def generate_seqs(env, outdir, c):
    cmd = ['python simulate_shm_on_tree.py',
           '--seed',
           c['seed'],
           '--mutability',
           '${SOURCES[0]}',
           '--substitution',
           '${SOURCES[1]}',
           '--use-v',
           '--use-immunized',
           '--locus',
           'igk',
           '--pct-mutated',
           c['pct_mutated'],
           '--path-to-annotations',
           CUI_DATA_PATH,
            '--path-to-metadata',
           CUI_DATA_PATH + '/meta.csv',
           '--motif-lens',
           MOTIF_LEN,
           '--output-germline-seqs ${TARGETS[0]}',
           '--output-seqs ${TARGETS[1]}']

    if c['tree_size']['size'] == 'one_big_tree':
        cmd += ['--n-clonal-families', c['tree_size']['n_clonal_families'],
            '--n-taxa', c['tree_size']['n_taxa']]
    else:
        cmd += ['--n-clonal-families', c['tree_size']['n_clonal_families']]

    return env.Command(
        [join(outdir, 'genes.csv'), join(outdir, 'seqs.csv')],
        c['write_gctree_truth'],
        ' '.join(map(str, cmd)))

nest.add(
    'data_type',
    [
        'imputed_ancestors',
        'all_data',
        'sample_random',
        #'sample_highest_mutated',
    ])

@nest.add_target_with_env(localenv)
def process_data(env, outdir, c):
    cmd = ['python preprocess_data.py',
               '--scratch-directory',
               SCRATCH_DIR,
               '--output-genes ${TARGETS[0]}',
               '--output-seqs ${TARGETS[1]}']

    cmd += ['--input-genes ${SOURCES[0]}',
        '--input-seqs ${SOURCES[1]}']

    if c['data_type'] == 'sample_random':
        cmd += ['--sample-from-family']
    elif c['data_type'] == 'imputed_ancestors':
        cmd += ['--impute-ancestors']
    elif c['data_type'] == 'sample_highest_mutated':
        cmd += ['--sample-highest-mutated']

    return env.Command(
        [
            join(outdir, 'processed_genes.csv'), join(outdir, 'processed_seqs.csv'),
        ],
        c['generate_seqs'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def fit_shazam(env, outdir, c):

    cmd = []
    if not c['data_type'] == 'sample_random' or not c['tree_size']['size'] == 'one_big_tree':
        # don't sample for the big family simulation
        cmd = ['python fit_shmulate_model.py',
               '--input-genes ${SOURCES[0]}',
               '--input-file ${SOURCES[1]}',
               '--model-pkl ${TARGETS[0]}',
               '--log-file ${TARGETS[1]}',
               '--center-median']

    return env.Command(
        [join(outdir, 'fitted_shazam.pkl'), join(outdir, 'log_shazam.txt')],
        c['process_data'],
        ' '.join(map(str, cmd)))

# fit survival
@nest.add_target_with_env(localenv)
def fit_survival(env, outdir, c):
    cmd = []
    motif_len = MOTIF_LEN
    left_flanks = MUTATING_POSITION
    if c['data_type'] == 'sample_random' or c['data_type'] == 'sample_highest_mutated':
        penalty_params = PENALTY_PARAMS_SAMPLE
    else:
        penalty_params = PENALTY_PARAMS

    if not c['data_type'] == 'sample_random' or not c['tree_size']['size'] == 'one_big_tree':
        # don't sample for the big family simulation
        cmd = ['python fit_samm.py',
               '--input-naive ${SOURCES[0]}',
               '--input-mutated ${SOURCES[1]}',
               '--seed',
               c['seed'],
               '--motif-lens',
               MOTIF_LEN,
               '--positions-mutating',
               MUTATING_POSITION,
               '--penalty-params',
               penalty_params,
               '--num-cpu-threads',
               10,
               '--num-jobs',
               80,
               '--burn-in',
               16,
               '--num-e-samples',
               4,
               '--sampling-rate',
               8,
               '--em-max-iters',
               10,
               '--num-val-burnin',
               16,
               '--num-val-samples',
               16,
               '--scratch-directory',
               SCRATCH_DIR,
               '--tuning-sample-ratio',
               0.2,
               '--omit-hessian',
               '--out-file ${TARGETS[0]}',
               '--log-file ${TARGETS[1]}']

    return env.Command(
        [join(outdir, 'fitted.pkl'), join(outdir, 'log.txt')],
        c['process_data'],
        ' '.join(map(str, cmd)))

@nest.add_target_with_env(localenv)
def convert_fit_shazam(env, outdir, c):

    def write_files(target, source, env):
        c = env['control']
        with open(str(source[0]), 'r') as f:
            theta_mut, (theta_target, theta_sub) = pickle.load(f)

        theta_mut[np.isnan(theta_mut)] = -np.inf

        feat_generator = HierarchicalMotifFeatureGenerator(motif_lens=[MOTIF_LEN])
        motif_list = feat_generator.motif_list

        theta_mut -= np.median(theta_mut)

        columns = 'rep motif col theta data model'.split()
        data = []
        for col in range(1):
            for idx, motif in enumerate(motif_list):
                data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'data': c['data_type'], 'model': 'SHazaM'}
                data_dict['theta'] = theta_mut[idx, col]
                data.append(data_dict)

        with open(str(target[0]), 'wb') as f:
            writer = csv.DictWriter(f, columns)
            writer.writeheader()
            writer.writerows(data)

    c['compare_models'].append(env.Command(
        join(outdir, 'fitted_shazam.csv'),
        c['fit_shazam'],
        write_files,
        control=c))

@nest.add_target_with_env(localenv)
def convert_fit_survival(env, outdir, c):

    def write_files(target, source, env):
        c = env['control']
        with open(str(source[0]), 'r') as f:
            fitted_models = pickle.load(f)
            best_model = pick_best_model(fitted_models)

        hier_feat_gen = HierarchicalMotifFeatureGenerator(
            motif_lens=best_model.motif_lens,
            feats_to_remove=best_model.model_masks.feats_to_remove,
            left_motif_flank_len_list=best_model.positions_mutating,
        )
        agg_feat_gen = HierarchicalMotifFeatureGenerator(
            motif_lens=[MOTIF_LEN],
            left_motif_flank_len_list=[[MUTATING_POSITION]],
        )
        theta = create_aggregate_theta(
            hier_feat_gen,
            agg_feat_gen,
            best_model.refit_theta,
            best_model.model_masks.zero_theta_mask_refit,
            best_model.refit_possible_theta_mask,
            keep_col0=False,
            add_targets=True,
        )
        theta -= np.median(theta)

        motif_list = agg_feat_gen.motif_list

        columns = 'rep motif col theta data model'.split()
        data = []
        for col in range(theta.shape[1]):
            for idx, motif in enumerate(motif_list):
                data_dict = {'rep': c['replicate'], 'motif': motif, 'col': col, 'data': c['data_type'], 'model': 'samm'}
                data_dict['theta'] = theta[idx, col]
                data.append(data_dict)

        with open(str(target[0]), 'wb') as f:
            writer = csv.DictWriter(f, columns)
            writer.writeheader()
            writer.writerows(data)

    c['compare_models'].append(env.Command(
        join(outdir, 'fitted_surv.csv'),
        c['fit_survival'],
        write_files,
        control=c))

nest.pop('data_type')

# concatenate into one file with parameter values and what type of data we obtained.
@nest.add_target_with_env(localenv)
def summarize(env, outdir, c):
    def cat_files(target, source, env):
        with open(str(target[0]), 'w') as catted_files:
            with open(str(source[0])) as first_file:
                # keep header from first file
                for line in first_file:
                    catted_files.write(line)

            for fname in source[1:]:
                with open(str(fname)) as next_file:
                    next(next_file)
                    for line in next_file:
                        catted_files.write(line)
    return env.Command(
        join(outdir, 'results.csv'),
        c['compare_models'],
        cat_files)
